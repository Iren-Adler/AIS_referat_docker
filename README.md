
# Оглавление {#оглавление .TOC-Heading}

[Эволюция виртуализации
[3](#эволюция-виртуализации)](#эволюция-виртуализации)

[Технология Docker: архитектура и ключевые компоненты
[4](#технология-docker-архитектура-и-ключевые-компоненты)](#технология-docker-архитектура-и-ключевые-компоненты)

[Docker-образы: структура и принципы формирования
[5](#docker-образы-структура-и-принципы-формирования)](#docker-образы-структура-и-принципы-формирования)

[Dockerfile: декларативное описание образа
[6](#dockerfile-декларативное-описание-образа)](#dockerfile-декларативное-описание-образа)

[Docker-контейнер [7](#docker-контейнер)](#docker-контейнер)

[Docker Hub и Docker Registry
[9](#docker-hub-и-docker-registry)](#docker-hub-и-docker-registry)

[Безопасность Docker [9](#безопасность-docker)](#безопасность-docker)

[Список литературы [11](#список-литературы)](#список-литературы)

# Эволюция виртуализации

**Эра до контейнеризации**\
Компании запускали приложения напрямую на физических серверах. Чтобы
справляться с ростом нагрузки и новыми задачами, приходилось постоянно
покупать более мощное оборудование «впрок», что вело к огромным тратам и
неэффективности --- серверы часто использовались лишь на 10-15% своей
мощности.

**Приход виртуализации**\
Технология виртуализации позволила на одном физическом сервере запускать
несколько изолированных виртуальных машин (ВМ). Это оптимизировало
использование ресурсов, так как можно было задействовать простаивающие
мощности. Однако у ВМ были серьёзные недостатки:

Каждой ВМ требовалась своя полноценная операционная система (ОС), что
потребляло много ресурсов.

Нужно было покупать и обслуживать лицензии на эти ОС.

Приложения на ВМ работали медленнее, чем на физическом железе («голом
металле»).

**Концепция контейнеризации**\
Решение пришло с контейнеризацией, основанной на технологии Linux
Containers (LXC). Её ключевая идея --- виртуализация на уровне ОС, а не
аппаратного обеспечения.

**Чем контейнеры лучше виртуальных машин:**

Контейнеру не нужна своя ОС. Все контейнеры на хосте используют общее
ядро основной операционной системы. Это делает их намного меньше и
быстрее (запускаются за секунды), позволяет разместить на одном сервере
в разы больше экземпляров, чем ВМ, и экономит ресурсы (CPU, память,
дисковое пространство).

Контейнер включает в себя само приложение и все его зависимости
(библиотеки, настройки). Это гарантирует, что приложение будет работать
абсолютно одинаково в любой среде: на ноутбуке разработчика, на тестовом
сервере или в продакшене. Проблема «у меня работает, а на сервере ---
нет» исчезает.

Отсутствие необходимости загружать полноценную ОС позволяет запускать и
останавливать контейнеры практически мгновенно.

Приложения в контейнерах изолированы друг от друга с помощью
«пространств имён», что ограничивает потенциальное распространение
вредоносного кода.

Контейнеры идеально подходят для практик непрерывной интеграции и
доставки (CI/CD), повышая скорость и надёжность разработки.

Они естественным образом соответствуют подходу, когда приложение состоит
из множества небольших сервисов (БД, веб-интерфейс и т.д.). Их легко и
быстро масштабировать вручную или автоматически с помощью инструментов
оркестрации, таких как Docker Swarm или Kubernetes.

Широкое распространение контейнеризации началось с
появления **Docker** в 2013 году --- простого и эффективного инструмента
для создания и управления контейнерами, который сделал технологию
доступной для масс.

# Технология Docker: архитектура и ключевые компоненты

Docker Engine: архитектура клиент-сервер

Docker Engine - то клиент-серверное приложение, которое можно загрузить

с Docker Hub или собрать вручную из исходного кода на GitHub.

**Docker REST API** - это программный интерфейс, который позволяет
управлять Docker. С ним можно взаимодействовать двумя основными
способами:

1)  Через **интерфейс командной строки (CLI)** 

основной и самый простой для пользователя метод.

2)  Через **скрипты или другие приложения**, которые автоматически
    отправляют команды API.

**Основная задача API** - принимать запросы от клиента и поручать их
выполнение **демону Docker** (фоновой службе, которая выполняет всю
тяжёлую работу: создаёт и управляет контейнерами, образами, сетями и
другими объектами)

**Архитектура Docker** построена по **клиент-серверной модели**:

Клиент Docker - это инструмент (вроде командной строки), с помощью
которого пользователь отдаёт команды.

Демон Docker (сервер) - это \"мозг\" системы, который выполняет эти
команды.

Клиент и демон могут работать как на одном компьютере, так и на разных
(в распределённой архитектуре). Они общаются между собой через **REST
API**, используя сокеты (Unix или сетевые).

**Существует две редакции Docker Engine:**

1)  Docker Engine Community Edition (CE) - бесплатная версия с открытым
    исходным кодом. Это идеальный старт для разработчиков и небольших
    команд

2)  Docker Engine Enterprise Edition (EE)** -** платная корпоративная
    версия. Она предназначена для компаний. Её ключевые отличия -
    соглашения об уровне обслуживания (SLA), которое гарантирует
    надёжность и доступность сервиса, предусматривая штрафы за нарушение
    этих гарантий.

# Docker-образы: структура и принципы формирования

Docker-образ - это неизменяемый шаблон, содержащий инструкции для
создания контейнера, он включает в себя:

- Файловую систему(слоистую)

- Зависимости приложения

- Конфигурацию среды выполнения

- Метаданные

Существуют ключевые принципы в образах -- это неизменяемость (образ
нельзя менять после создания), каждый образ состоит из набора read-only
слоев, слои кешируеются и используются разными образами, образы имеют
теги для контроля версий

Каждая команда в **Dockerfile** создает новый слой:

**FROM ubuntu:22.04 \# СЛОЙ 1: Базовый образ (основная ОС)**

**RUN apt-get update && \\ \# СЛОЙ 2: Обновление пакетов**

**apt-get install -y nginx**

**COPY nginx.conf /etc/nginx/ \# СЛОЙ 3: Копирование конфигурации**

**EXPOSE 80 \# Метаданные (не создает слой)**

**CMD \[\"nginx\", \"-g\", \"daemon off;\"\] \# Метаданные**

Есть некоторые преимущества слоистой архитектуры - она экономит дисковое
пространство (т.к. общие слои не дублируются), происходит ускорение
сборки (т.к. кэшированные слои не пересобираются), передаются только
измененные слои

\# Просмотр истории образа и его слоев

**docker history myimage:latest**

# Dockerfile: декларативное описание образа

**FROM** - определяет базовый образ:

FROM ubuntu:22.04

FROM python:3.11-slim

FROM node:18-alpine

FROM nginx:1.23.3-alpine -- специфичные версии

**RUN** - выполняет команды во время сборки:

RUN apt-get update

\# Цепочка команд (рекомендуется для уменьшения слоев)

RUN apt-get update && \\

apt-get install -y python3 python3-pip && \\

rm -rf /var/lib/apt/lists/\* \# Очистка кэша для уменьшения размера

**COPY vs ADD** - копирование файлов:

\# COPY - простое копирование

COPY requirements.txt /app/

COPY . /app/ \# Копирование всей текущей директории

\# ADD - дополнительные возможности

ADD https://example.com/file.tar.gz /tmp/ \# Загрузка из URL

ADD file.tar.gz /tmp/ \# Автоматическое распаковка tar

**WORKDIR** - установка рабочей директории:

WORKDIR /app \# Все последующие команды выполняются из этой директории

**ENV** - установка переменных окружения:

ENV NODE_ENV=production

ENV PORT=8080 APP_VERSION=1.0.0

**EXPOSE** - декларация используемых портов:

EXPOSE 80 \# HTTP

EXPOSE 443 \# HTTPS

EXPOSE 3000 \# Приложение Node.js

**CMD ENTRYPOINT** - команда запуска:

\# CMD - аргументы по умолчанию (можно переопределить при запуске)

CMD \[\"python\", \"app.py\"\]

\# ENTRYPOINT - основная команда (аргументы добавляются)

ENTRYPOINT \[\"python\"\]

CMD \[\"app.py\"\] \# Будет выполнено: python app.py

# Docker-контейнер

Docker-контейнер --- это запущенный экземпляр образа с добавленным
поверх него записываемым слоем (R/W layer). В то время как образ
является шаблоном (template), контейнер --- это исполняемый экземпляр.

Сравнительная характеристика:

| **Аспект**         | **Образ (Image)**          | **Контейнер (Container)**  |
|--------------------|----------------------------|----------------------------|
| **Состояние**      | Read-Only (только для чтения) | Read-Write (чтение/запись) |
| **Изменяемость**   | Иммутабельный (неизменяемый) | Мутабельный (изменяемый)   |
| **Хранение**       | В реестре/файловой системе | В памяти и временных файлах |
| **Количество**     | Один образ --- много контейнеров | Много экземпляров от одного образа |
| **Жизненный цикл** | Постоянный                 | Временный (эфемерный)      |

#### Описание состояний

1.  **Created**  контейнер создан, но не запущен
2.  **Running** контейнер выполняется
3.  **Paused**  процессы приостановлены (cgroups freezer)
4.  **Restarting** перезапуск после остановки
5.  **Exited** выполнение завершено
6.  **Dead** неудачная попытка удаления/ошибка

**Создание и запуск**

docker run \[OPTIONS\] IMAGE \[COMMAND\] \[ARG\...\]

Примеры:

docker run -d \--name webserver nginx:alpine

docker run -it \--rm ubuntu:22.04 bash

docker run -p 8080:80 -v ./data:/data myapp:latest

**Мониторинг и инспекция**\

Список контейнеров

docker ps \# Только запущенные

docker ps -a \# Все контейнеры

docker ps \--filter \"status=running\"

docker ps \--format \"table {{.Names}}\\t{{.Status}}\\t{{.Ports}}\"

Логи контейнера

docker logs webserver

docker logs -f webserver \# Follow (потоковый вывод)

docker logs \--tail 50 webserver

docker logs \--since 10m webserver

Информация о контейнере

docker inspect webserver

docker inspect \--format=\'{{.NetworkSettings.IPAddress}}\' webserver

docker inspect -f \'{{json .State}}\' webserver \| jq

Статистика использования ресурсов

docker stats

docker stats \--no-stream

docker stats \--format \"table {{.Name}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\"

Процессы внутри контейнера

docker top webserver

docker exec webserver ps aux

# Docker Hub и Docker Registry

Реестр (Registry)-это система хранения и доставки данных. В случае с Docker
речь идет о хранении образов с использованием тегов. Помимо сервиса
Docker Registry для этой цели можно использовать сторонний публичный или
закрытый (private) реестр

У одного образа может быть несколько версий с разными тегами. В реестр
образы загружаются с помощью команды push, а извлекаются из него помощью
команды pull.

Docker Hub - это облачный репозиторий для создания, тестирования,
хранения и распространения образов контейнеров, облачная версия Docker
Registry.

Реестр может стать отличным дополнением системы CI/CD. Обычно это
происходит следующим образом: фиксация в системе управления версиями
приводит к сборке в системе непрерывной интеграции (СI), и если сборка
выполнена успешно, в реестр отправляется новый образ. Уведомление от
реестра автоматически запускает развертывание в промежуточной среде.
Кроме того, можно отправлять уведомление о новом образе в другие
системы.

# Безопасность Docker 

1\. Безопасность на уровне ядра (Пространства имён и контрольные группы)

Контейнеры Docker используют механизмы ядра Linux: пространства имён для
изоляции процессов и контрольные группы (cgroups) для ограничения и
учёта ресурсов (CPU, память). По умолчанию каждый контейнер имеет
изолированную сеть, а связь между контейнерами на одном хосте происходит
через внутренние \"мосты\". Эти встроенные меры предотвращают
автоматическое распространение вредоносного кода между контейнерами,
затрудняют DoS-атаки и обеспечивают стабильность системы.

2\. Поверхность атаки демона Docker

Демон Docker обычно работает с правами суперпользователя (root), что
создаёт риски

1\) Доступ к демону должны иметь только доверенные пользователи.

2\) Контейнер может иметь общие с хост-системой папки, что потенциально
позволяет изменить файловую систему хоста из контейнера. Это требует
особых мер предосторожности, особенно при автоматизированном
развёртывании через API.

3\) Хотя теоретически можно запустить демон без прав root, на практике
это сильно ограничивает функциональность. Однако сам Docker выполняет
многие задачи, требующие прав root, внутри своей инфраструктуры, что
позволяет контейнерам часто работать с ограниченными возможностями,
косвенно повышая безопасность.

3\. Конфигурация контейнера (Профиль безопасности)

Уровень безопасности можно тонко настраивать для каждого контейнера:

- Следовать принципу минимальных привилегий: отключать все лишние
  системные возможности (capabilities), оставляя только необходимые для
  работы процесса.

- Использовать Docker Content Trust (DCT) для запуска только тех
  образов, которые имеют цифровую подпись, гарантирующую их подлинность
  и неизменность.

4\. Усиление безопасности с помощью сторонних инструментов

Безопасность Docker не ограничивается его встроенными функциями. Её
можно значительно усилить с помощью стандартных инструментов защиты на
уровне всей ОС (например, SELinux, AppArmor, инструменты аудита),
которые не требуют модификации Docker и определения политик безопасности
в системах контроля доступа.

# Список литературы

1)  Docker, Inc. Документация Docker \[Электронный ресурс\]. -- URL:
    https://docs.docker.com.
2)  Бархам, П. Xen and the Art of Virtualization / П. Бархам, Б. Дрег,
    К. Фрейзер \[и др.\] // Proceedings of the 19th ACM Symposium on
    Operating Systems Principles. -- Болтон-Лэндинг (США). -- 2003. --
    С. 164--177.
3)  Тёрнбулл, Дж. The Docker Book: Containerization is the New
    Virtualization / Дж. Тёрнбулл. -- Сидней: James Turnbull, 2019. --
    442 с.
4)  Меркель, Д. Docker: Lightweight Linux Containers for Consistent
    Development and Deployment / Д. Меркель // Linux Journal. --
    Хьюстон. -- 2014. -- № 239. -- С. 2--11.
